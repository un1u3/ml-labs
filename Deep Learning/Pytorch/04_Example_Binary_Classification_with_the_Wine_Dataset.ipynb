{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhEa/sYOtsxDdokv64LAG/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/un1u3/ml-labs/blob/main/Deep%20Learning/Pytorch/04_Example_Binary_Classification_with_the_Wine_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "nLMMJf-iyuN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "Py2fsvl_1sOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the wine dataser\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# convert the task to binary classification\n",
        "y = (y == 0).astype(float)\n",
        "\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "# scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scale  = scaler.fit_transform(X_train)\n",
        "X_test_scale = scaler.transform(X_test)\n",
        "\n",
        "# convert to Pytorch tensor\n",
        "X_train = torch.tensor(X_train,dtype = torch.float)\n",
        "y_train = torch.tensor(y_train,dtype= float).unsqueeze(1)\n",
        "X_test = torch.tensor(X_test,dtype=float)\n",
        "y_test = torch.tensor(y_test,dtype=float).unsqueeze(1)\n",
        "\n",
        "\n",
        "# createdata loders\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "test_data = TensorDataset(X_test,y_test)\n",
        "\n",
        "train_loader = DataLoader(train_data,batch_size=32,shuffle=True)\n",
        "test_loader = DataLoader(test_data,batch_size=32,shuffle=False)\n"
      ],
      "metadata": {
        "id": "e0oXcrrl18CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define a Neural Network"
      ],
      "metadata": {
        "id": "a8t4fVaD2sIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class WineClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(WineClassifier,self).__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(13,32), # Input layer : 13 features to 32 neurons\n",
        "        nn.ReLU(), # activation function\n",
        "        nn.Linear(32,16), # hidden  layer\n",
        "        nn.ReLU(), # activation function\n",
        "        nn.Linear(16,1), # Output layer: 1 neuron for binary classification\n",
        "        nn.Sigmoid() # Sigmoid activation for binary output\n",
        "        )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.network(x)"
      ],
      "metadata": {
        "id": "jLxT8_Ya2sme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = WineClassifier()"
      ],
      "metadata": {
        "id": "cH9NBv3_GNEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaTgh6R1GPTx",
        "outputId": "c53c89ba-ea75-4f76-efae-887e7e51769e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WineClassifier(\n",
              "  (network): Sequential(\n",
              "    (0): Linear(in_features=13, out_features=32, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (3): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define loss function and optimizer"
      ],
      "metadata": {
        "id": "57uwelruGQca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "Ijzdt6-PGaqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "7HkFK8VEGq7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "epochs = 69\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        X_batch, y_batch = batch\n",
        "\n",
        "        # Forward pass\n",
        "        predictions = model(X_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        loss.backward()        # Compute gradients\n",
        "        optimizer.step()       # Update parameters\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Calculate average training loss\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
        "        for batch in test_loader: # Changed val_loader to test_loader\n",
        "            X_batch, y_batch = batch\n",
        "            predictions = model(X_batch)\n",
        "            val_loss += criterion(predictions, y_batch).item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            predicted_labels = (predictions > 0.5).float()\n",
        "            correct += (predicted_labels == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "    avg_val_loss = val_loss / len(test_loader) # Changed val_loader to test_loader\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    print(f\"  Training Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"  Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4egm-__GxjW",
        "outputId": "a4426613-f84b-4977-9699-5d184a8933f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/69\n",
            "  Training Loss: 31.4749\n",
            "  Validation Loss: 53.8664, Accuracy: 0.6111\n",
            "Epoch 2/69\n",
            "  Training Loss: 28.7650\n",
            "  Validation Loss: 53.8666, Accuracy: 0.6111\n",
            "Epoch 3/69\n",
            "  Training Loss: 26.5372\n",
            "  Validation Loss: 53.8667, Accuracy: 0.6111\n",
            "Epoch 4/69\n",
            "  Training Loss: 27.1815\n",
            "  Validation Loss: 53.8668, Accuracy: 0.6111\n",
            "Epoch 5/69\n",
            "  Training Loss: 29.1552\n",
            "  Validation Loss: 53.8670, Accuracy: 0.6111\n",
            "Epoch 6/69\n",
            "  Training Loss: 28.7278\n",
            "  Validation Loss: 53.8672, Accuracy: 0.6111\n",
            "Epoch 7/69\n",
            "  Training Loss: 27.0927\n",
            "  Validation Loss: 53.8673, Accuracy: 0.6111\n",
            "Epoch 8/69\n",
            "  Training Loss: 29.2368\n",
            "  Validation Loss: 53.8675, Accuracy: 0.6111\n",
            "Epoch 9/69\n",
            "  Training Loss: 28.7296\n",
            "  Validation Loss: 53.8676, Accuracy: 0.6111\n",
            "Epoch 10/69\n",
            "  Training Loss: 27.3445\n",
            "  Validation Loss: 53.8678, Accuracy: 0.6111\n",
            "Epoch 11/69\n",
            "  Training Loss: 28.3686\n",
            "  Validation Loss: 53.8679, Accuracy: 0.6111\n",
            "Epoch 12/69\n",
            "  Training Loss: 28.5079\n",
            "  Validation Loss: 53.8680, Accuracy: 0.6111\n",
            "Epoch 13/69\n",
            "  Training Loss: 29.4324\n",
            "  Validation Loss: 53.8681, Accuracy: 0.6111\n",
            "Epoch 14/69\n",
            "  Training Loss: 27.0748\n",
            "  Validation Loss: 53.8683, Accuracy: 0.6111\n",
            "Epoch 15/69\n",
            "  Training Loss: 31.4178\n",
            "  Validation Loss: 53.8685, Accuracy: 0.6111\n",
            "Epoch 16/69\n",
            "  Training Loss: 27.9090\n",
            "  Validation Loss: 53.8686, Accuracy: 0.6111\n",
            "Epoch 17/69\n",
            "  Training Loss: 28.9548\n",
            "  Validation Loss: 53.8687, Accuracy: 0.6111\n",
            "Epoch 18/69\n",
            "  Training Loss: 28.5821\n",
            "  Validation Loss: 53.8689, Accuracy: 0.6111\n",
            "Epoch 19/69\n",
            "  Training Loss: 29.4155\n",
            "  Validation Loss: 53.8690, Accuracy: 0.6111\n",
            "Epoch 20/69\n",
            "  Training Loss: 29.3644\n",
            "  Validation Loss: 53.8691, Accuracy: 0.6111\n",
            "Epoch 21/69\n",
            "  Training Loss: 27.9711\n",
            "  Validation Loss: 53.8692, Accuracy: 0.6111\n",
            "Epoch 22/69\n",
            "  Training Loss: 28.6948\n",
            "  Validation Loss: 53.8693, Accuracy: 0.6111\n",
            "Epoch 23/69\n",
            "  Training Loss: 30.2082\n",
            "  Validation Loss: 53.8695, Accuracy: 0.6111\n",
            "Epoch 24/69\n",
            "  Training Loss: 28.0432\n",
            "  Validation Loss: 53.8696, Accuracy: 0.6111\n",
            "Epoch 25/69\n",
            "  Training Loss: 30.3156\n",
            "  Validation Loss: 53.8697, Accuracy: 0.6111\n",
            "Epoch 26/69\n",
            "  Training Loss: 27.8929\n",
            "  Validation Loss: 53.8698, Accuracy: 0.6111\n",
            "Epoch 27/69\n",
            "  Training Loss: 29.9438\n",
            "  Validation Loss: 53.8699, Accuracy: 0.6111\n",
            "Epoch 28/69\n",
            "  Training Loss: 27.0899\n",
            "  Validation Loss: 53.8701, Accuracy: 0.6111\n",
            "Epoch 29/69\n",
            "  Training Loss: 27.8158\n",
            "  Validation Loss: 53.8702, Accuracy: 0.6111\n",
            "Epoch 30/69\n",
            "  Training Loss: 28.7186\n",
            "  Validation Loss: 53.8703, Accuracy: 0.6111\n",
            "Epoch 31/69\n",
            "  Training Loss: 27.8803\n",
            "  Validation Loss: 53.8704, Accuracy: 0.6111\n",
            "Epoch 32/69\n",
            "  Training Loss: 29.4851\n",
            "  Validation Loss: 53.8705, Accuracy: 0.6111\n",
            "Epoch 33/69\n",
            "  Training Loss: 29.5028\n",
            "  Validation Loss: 53.8707, Accuracy: 0.6111\n",
            "Epoch 34/69\n",
            "  Training Loss: 27.4251\n",
            "  Validation Loss: 53.8709, Accuracy: 0.6111\n",
            "Epoch 35/69\n",
            "  Training Loss: 26.6220\n",
            "  Validation Loss: 53.8710, Accuracy: 0.6111\n",
            "Epoch 36/69\n",
            "  Training Loss: 27.9680\n",
            "  Validation Loss: 53.8711, Accuracy: 0.6111\n",
            "Epoch 37/69\n",
            "  Training Loss: 28.9129\n",
            "  Validation Loss: 53.8712, Accuracy: 0.6111\n",
            "Epoch 38/69\n",
            "  Training Loss: 29.6170\n",
            "  Validation Loss: 53.8714, Accuracy: 0.6111\n",
            "Epoch 39/69\n",
            "  Training Loss: 28.2307\n",
            "  Validation Loss: 53.8715, Accuracy: 0.6111\n",
            "Epoch 40/69\n",
            "  Training Loss: 30.1944\n",
            "  Validation Loss: 53.8716, Accuracy: 0.6111\n",
            "Epoch 41/69\n",
            "  Training Loss: 29.1112\n",
            "  Validation Loss: 53.8717, Accuracy: 0.6111\n",
            "Epoch 42/69\n",
            "  Training Loss: 29.6578\n",
            "  Validation Loss: 53.8718, Accuracy: 0.6111\n",
            "Epoch 43/69\n",
            "  Training Loss: 28.0740\n",
            "  Validation Loss: 53.8719, Accuracy: 0.6111\n",
            "Epoch 44/69\n",
            "  Training Loss: 29.0361\n",
            "  Validation Loss: 53.8721, Accuracy: 0.6111\n",
            "Epoch 45/69\n",
            "  Training Loss: 29.9766\n",
            "  Validation Loss: 53.8722, Accuracy: 0.6111\n",
            "Epoch 46/69\n",
            "  Training Loss: 30.4230\n",
            "  Validation Loss: 53.8723, Accuracy: 0.6111\n",
            "Epoch 47/69\n",
            "  Training Loss: 27.1892\n",
            "  Validation Loss: 53.8724, Accuracy: 0.6111\n",
            "Epoch 48/69\n",
            "  Training Loss: 27.0086\n",
            "  Validation Loss: 53.8725, Accuracy: 0.6111\n",
            "Epoch 49/69\n",
            "  Training Loss: 28.9177\n",
            "  Validation Loss: 53.8726, Accuracy: 0.6111\n",
            "Epoch 50/69\n",
            "  Training Loss: 27.4311\n",
            "  Validation Loss: 53.8727, Accuracy: 0.6111\n",
            "Epoch 51/69\n",
            "  Training Loss: 27.9734\n",
            "  Validation Loss: 53.8729, Accuracy: 0.6111\n",
            "Epoch 52/69\n",
            "  Training Loss: 29.4234\n",
            "  Validation Loss: 53.8730, Accuracy: 0.6111\n",
            "Epoch 53/69\n",
            "  Training Loss: 30.6975\n",
            "  Validation Loss: 53.8731, Accuracy: 0.6111\n",
            "Epoch 54/69\n",
            "  Training Loss: 30.8473\n",
            "  Validation Loss: 53.8733, Accuracy: 0.6111\n",
            "Epoch 55/69\n",
            "  Training Loss: 28.9477\n",
            "  Validation Loss: 53.8734, Accuracy: 0.6111\n",
            "Epoch 56/69\n",
            "  Training Loss: 28.8101\n",
            "  Validation Loss: 53.8736, Accuracy: 0.6111\n",
            "Epoch 57/69\n",
            "  Training Loss: 29.1612\n",
            "  Validation Loss: 53.8737, Accuracy: 0.6111\n",
            "Epoch 58/69\n",
            "  Training Loss: 30.9078\n",
            "  Validation Loss: 53.8738, Accuracy: 0.6111\n",
            "Epoch 59/69\n",
            "  Training Loss: 29.5724\n",
            "  Validation Loss: 53.8739, Accuracy: 0.6111\n",
            "Epoch 60/69\n",
            "  Training Loss: 30.3822\n",
            "  Validation Loss: 53.8740, Accuracy: 0.6111\n",
            "Epoch 61/69\n",
            "  Training Loss: 29.3204\n",
            "  Validation Loss: 53.8741, Accuracy: 0.6111\n",
            "Epoch 62/69\n",
            "  Training Loss: 28.2315\n",
            "  Validation Loss: 53.8743, Accuracy: 0.6111\n",
            "Epoch 63/69\n",
            "  Training Loss: 26.6326\n",
            "  Validation Loss: 53.8744, Accuracy: 0.6111\n",
            "Epoch 64/69\n",
            "  Training Loss: 29.6862\n",
            "  Validation Loss: 53.8745, Accuracy: 0.6111\n",
            "Epoch 65/69\n",
            "  Training Loss: 30.2743\n",
            "  Validation Loss: 53.8747, Accuracy: 0.6111\n",
            "Epoch 66/69\n",
            "  Training Loss: 27.8710\n",
            "  Validation Loss: 53.8748, Accuracy: 0.6111\n",
            "Epoch 67/69\n",
            "  Training Loss: 30.1432\n",
            "  Validation Loss: 53.8749, Accuracy: 0.6111\n",
            "Epoch 68/69\n",
            "  Training Loss: 28.2418\n",
            "  Validation Loss: 53.8751, Accuracy: 0.6111\n",
            "Epoch 69/69\n",
            "  Training Loss: 30.6528\n",
            "  Validation Loss: 53.8752, Accuracy: 0.6111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "MCBayRaIIau2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}